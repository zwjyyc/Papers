# Papers

Universal Language Model Fine-tuning for Text Classification （2018/5/16）

Towards Robust Neural Machine Translation (2018/5/17)

Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension (2018/5/17)

SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines (2018/5/17)

Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting （2018/5/29）

Toward Abstractive Summarization Using Semantic Representations （2018/5/29）

Global-Locally Self-Attentive Dialogue State Tracker （2018/5/29）

Densely Connected Convolutional Networks （2018/6/7）

Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information （2018/6/7）

Universal Sentence Encoder (2018/6/9)

A Decomposable Attention Model for Natural Language Inference （2018/6/9）

UMBC EBIQUITY-CORE: Semantic Textual Similarity Systems （2018/6/11）

A Simple Method for Commonsense Reasoning (2018/6/11)

Towards Binary-Valued Gates for Robust LSTM Training （2018/6/11）

Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text Corpora (2018/6/11)

The Natural Language Decathlon: Multitask Learning as Question Answering （2018/6/25）
#### Though not explicitly designed for any one task, MQAN proves to be a strong model in the single-task setting as well, achieving state-of-the-art results on the semantic parsing component of decaNLP.


# Dialogue Papers
TALKING TO MACHINES (STATISTICALLY SPEAKING) （2018/6/24）

A Network-based End-to-End Trainable Task-oriented Dialogue System (2018/6/25)

Key-Value Retrieval Networks for Task-Oriented Dialogue （2018/7/23）

A User Simulator for Task-Completion Dialogues （2018/7/23）

Deal or No Deal? End-to-End Learning for Negotiation Dialogues （2018/8/11）


# Slides 
Attention is All you Need \\
https://nlp.stanford.edu/seminar/details/lkaiser.pdf

Deep	Learning	for	Natural	Language	Generation	&	End-to-End	Dialogue	Modeling \\

